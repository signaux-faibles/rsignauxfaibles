% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/model_train.R
\name{train_xgboost}
\alias{train_xgboost}
\title{Train an xgboost model}
\usage{
train_xgboost(train_data, outcome, validation_data = NULL,
  learn_rate = 0.1, max_depth = 4, ntrees = 60,
  min_child_weight = 1, seed = 123)
}
\arguments{
\item{train_data}{\code{data.frame} \cr données d'entraînement, sous la forme d'un H2OFrame}

\item{outcome}{\code{character(1)} \cr Nom de la variable qui sert de cible
d'apprentissage}

\item{validation_data}{\code{H2OFrame} \cr Données d'évaluation, sous la forme d'un H2OFrame}

\item{learn_rate}{\code{numeric(1)} \cr}

\item{max_depth}{\code{integer(1)} \cr  Specify the maximum tree depth. Higher
values will make the model more complex and can lead to overfitting.
Setting this value to 0 specifies no limit.}

\item{ntrees}{\code{integer(1)} \cr Specify the number of trees to build.}

\item{min_child_weight}{\code{integer(1)} \cr Specify the minimum number of
observations for a leaf.}

\item{seed}{\code{integer(1)} \cr Graine aléatoire pour que les opérations
aléatoires soient reproductibles.}
}
\value{
\code{H2OBinomialModel} \cr
}
\description{
Trains a light gradient boosting model on training data.
}
