---
title: "Light gradient boosting pipe reference model on new data"
author: "Pierre Camilleri"
date: "3 juin 2019"
output: html_document
---

## Imports
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
h2o::h2o.no_progress()
library(mlr)
# Script parameters
devtools::load_all()
database <- "test_signauxfaibles"
collection <- "Features"
actual_period <- as.Date("2019-05-01")
last_batch <- "1906_6"
min_effectif <- 10
retrain_model <- TRUE
export_type <- c("csv", "mongodb")
sample_size <- 10000
```

```{r}
connect_to_h2o()
```

```{r}
# QUICKFIX
fields_without_undef <- get_fields(training = FALSE)
fields_without_undef <- fields_without_undef[
  !fields_without_undef %in% c("code_naf")
  ]
###
task <- sf_task(
  verbose = TRUE,
  database,
  collection,
  experiment_name = "Reference evaluation canvas",
  experiment_description = "This experiment fixes the conditions for the evaluation of a new algorithm compared to former versions"
)

task <- load_hist_data(
  task = task,
  batch = last_batch,
  subsample = sample_size,
  fields = fields_without_undef[1:10]
)
task <- split_data(task, fracs = c(1,0,0))
task <- prepare(task, data_names = c("train_data"))
task[["model_parameters"]] <- list(
  learn_rate = 0.044849,
  max_depth = 8,
  ntrees = 185,
  min_child_weight = 6
  )
task <- train(task)
task <- load_new_data(task,
task <- predict(task, data_names = "validation_data")
task <- evaluate(task, data_name = "validation_data")
task <- log(task)
```

# OU
```{r}
task <- evaluate(task, data_name = "validation_data", eval_function = custom_eval_urssaf())
```

