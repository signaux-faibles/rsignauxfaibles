---
title: "Light gradient boosting pipe reference model on new data"
author: "Pierre Camilleri"
date: "3 juin 2019"
output: html_document
---

## Imports
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
h2o::h2o.no_progress()
library(mlr)
# Script parameters
devtools::load_all()
database <- "test_signauxfaibles"
collection <- "Features"
actual_period <- as.Date("2019-05-01")
last_batch <- "1906_7"
min_effectif <- 10
retrain_model <- TRUE
export_type <- c("csv", "mongodb")
sample_size <- 10000
```

```{r}
connect_to_h2o()
```

```{r}
task <- sf_task(
  verbose = TRUE,
  database,
  collection,
  experiment_name = "Reference evaluation canvas",
  experiment_description = "This experiment fixes the conditions for the evaluation of a new algorithm compared to former versions"
)

task <- load_new_data(
  task = task,
  periods = actual_period,
  batch = last_batch
)
task <- load_hist_data(
  task = task,
  subsample = 800000,
  batch = last_batch
  )
task <- split_data(task, fracs = c(1,0,0))
task <- prepare(task, data_names = c("train_data"))
 task[["model_parameters"]] <- list(
   learn_rate = 0.044612,
   max_depth = 7,
   ntrees = 237,
   min_child_weight = 3
   )
task <- train(task)
task <- prepare(task, data_names = c("new_data"))
task <- predict(task, data_names = "new_data")
task <- evaluate(task, data_name = "validation_data")
save(task)
export(task, "mongodb", batch = last_batch)
```

# OU
```{r}
task <- evaluate(task, data_name = "validation_data", eval_function = custom_eval_urssaf())
```

